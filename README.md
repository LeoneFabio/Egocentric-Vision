# Egocentric-Vision
This project leverages the Ego4D NLQ benchmark to process egocentric video data using VSLNet, predicting start/end timestamps for queries. It extends this with a videoQA model for generating textual answers, enabling deeper interaction with egocentric video and natural language tasks.
